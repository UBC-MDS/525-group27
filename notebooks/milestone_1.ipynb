{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RainFall Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import requests\n",
    "from urllib.request import urlretrieve\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Partitioned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary metadata\n",
    "article_id = 14096681  # this is the unique identifier of the article on figshare\n",
    "url = f\"https://api.figshare.com/v2/articles/{article_id}\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "output_directory = \"../data/rainfall/partitions/\"\n",
    "\n",
    "\n",
    "# Retrieve the article metadata\n",
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "data = json.loads(response.text)  # this contains all the articles data, feel free to check it out\n",
    "files = data[\"files\"]             # this is just the data about the files, which is what we want\n",
    "\n",
    "\n",
    "# Zip to Folder Unzip\n",
    "files_to_dl = [\"data.zip\"]  # feel free to add other files here\n",
    "for file in files:\n",
    "    if file[\"name\"] in files_to_dl:\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "        urlretrieve(file[\"download_url\"], output_directory + file[\"name\"])\n",
    "        \n",
    "with zipfile.ZipFile(os.path.join(output_directory, \"data.zip\"), 'r') as f:\n",
    "    f.extractall(output_directory)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "files_to_combine = glob.glob(output_directory + \"*.csv\")\n",
    "files_to_combine.remove(output_directory + \"observed_daily_rainfall_SYD.csv\")\n",
    "df = pd.concat(\n",
    "    (pd.read_csv(file, index_col=0)\n",
    "                .assign(model=re.findall(r'[^\\/&\\\\]+(?=_daily_rainfall_NSW\\.)', file)[0])\n",
    "                for file in files_to_combine)\n",
    "    )\n",
    "\n",
    "# Save the combined data\n",
    "data_path = \"../data/rainfall/\"\n",
    "os.makedirs(data_path + \"combined/\", exist_ok=True)\n",
    "df.to_csv(data_path + \"combined/rainfall_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a simple EDA in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.dataset as ds\n",
    "import pyarrow as pa\n",
    "import pandas as pd\n",
    "import pyarrow \n",
    "from pyarrow import csv\n",
    "import rpy2_arrow.pyarrow_rarrow as pyra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "suppressMessages(library(dplyr, warn.conflicts = FALSE))\n",
    "suppressMessages(library(arrow, warn.conflicts = FALSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.6 s, sys: 8.17 s, total: 48.8 s\n",
      "Wall time: 52.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\"../data/rainfall/combined/rainfall_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.8 s, sys: 3.09 s, total: 9.89 s\n",
      "Wall time: 7.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.to_feather(data_path +\"combined/rainfall_data.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.69 ms, sys: 11.1 ms, total: 18.8 ms\n",
      "Wall time: 139 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R\n",
    "ds <- open_dataset(\"../data/rainfall/combined/rainfall_data.feather\", format=\"feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# A tibble: 62,467,843 × 7\n",
      "   time                lat_min lat_max lon_min lon_max `rain (mm/day)` model    \n",
      "   <chr>                 <dbl>   <dbl>   <dbl>   <dbl>           <dbl> <chr>    \n",
      " 1 1957-08-09 12:00:00   -33.6   -31.7    143.    145.        6.33e+ 0 MPI-ESM-…\n",
      " 2 1957-08-10 12:00:00   -33.6   -31.7    143.    145.        9.83e- 1 MPI-ESM-…\n",
      " 3 1957-08-11 12:00:00   -33.6   -31.7    143.    145.        4.18e+ 0 MPI-ESM-…\n",
      " 4 1957-08-12 12:00:00   -33.6   -31.7    143.    145.        1.83e- 1 MPI-ESM-…\n",
      " 5 1957-08-13 12:00:00   -33.6   -31.7    143.    145.        3.71e-13 MPI-ESM-…\n",
      " 6 1957-08-14 12:00:00   -33.6   -31.7    143.    145.        1.75e- 3 MPI-ESM-…\n",
      " 7 1957-08-15 12:00:00   -33.6   -31.7    143.    145.        2.89e+ 0 MPI-ESM-…\n",
      " 8 1957-08-16 12:00:00   -33.6   -31.7    143.    145.        4.10e-13 MPI-ESM-…\n",
      " 9 1957-08-17 12:00:00   -33.6   -31.7    143.    145.        4.03e-13 MPI-ESM-…\n",
      "10 1957-08-18 12:00:00   -33.6   -31.7    143.    145.        3.73e-13 MPI-ESM-…\n",
      "# … with 62,467,833 more rows\n",
      "CPU times: user 8.96 s, sys: 3.88 s, total: 12.8 s\n",
      "Wall time: 12.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R\n",
    "print(ds %>% collect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arrow exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34 s, sys: 2.11 s, total: 36.1 s\n",
      "Wall time: 35.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dataset = ds.dataset(\"../data/rainfall/combined/rainfall_data.csv\", format=\"csv\")\n",
    "table = dataset.to_table()\n",
    "r_table = pyra.converter.py2rpy(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# A tibble: 62,467,843 × 7\n",
      "   time                lat_min lat_max lon_min lon_max `rain (mm/day)` model    \n",
      "   <dttm>                <dbl>   <dbl>   <dbl>   <dbl>           <dbl> <chr>    \n",
      " 1 1889-01-01 04:00:00   -35.4   -33.6    142.    143.        4.24e-13 MPI-ESM-…\n",
      " 2 1889-01-02 04:00:00   -35.4   -33.6    142.    143.        4.22e-13 MPI-ESM-…\n",
      " 3 1889-01-03 04:00:00   -35.4   -33.6    142.    143.        4.50e-13 MPI-ESM-…\n",
      " 4 1889-01-04 04:00:00   -35.4   -33.6    142.    143.        4.25e-13 MPI-ESM-…\n",
      " 5 1889-01-05 04:00:00   -35.4   -33.6    142.    143.        4.27e-13 MPI-ESM-…\n",
      " 6 1889-01-06 04:00:00   -35.4   -33.6    142.    143.        4.20e-13 MPI-ESM-…\n",
      " 7 1889-01-07 04:00:00   -35.4   -33.6    142.    143.        4.19e-13 MPI-ESM-…\n",
      " 8 1889-01-08 04:00:00   -35.4   -33.6    142.    143.        4.56e-13 MPI-ESM-…\n",
      " 9 1889-01-09 04:00:00   -35.4   -33.6    142.    143.        2.53e+ 0 MPI-ESM-…\n",
      "10 1889-01-10 04:00:00   -35.4   -33.6    142.    143.        4.12e- 2 MPI-ESM-…\n",
      "# … with 62,467,833 more rows\n",
      "Time difference of 0.0002830029 secs\n",
      "CPU times: user 2.97 s, sys: 2.32 s, total: 5.29 s\n",
      "Wall time: 5.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R -i r_table\n",
    "start_time <- Sys.time()\n",
    "suppressMessages(library(dplyr))\n",
    "result <- r_table \n",
    "end_time <- Sys.time()\n",
    "print(result %>% collect())\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.3 s, sys: 4.76 s, total: 21.1 s\n",
      "Wall time: 20.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.to_parquet(\"../data/rainfall/combined/rainfall_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.93 ms, sys: 9.21 ms, total: 16.1 ms\n",
      "Wall time: 17.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R\n",
    "ds <- open_dataset(\"../data/rainfall/combined/rainfall_data.parquet\", format=\"parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# A tibble: 62,467,843 × 7\n",
      "   time                lat_min lat_max lon_min lon_max `rain (mm/day)` model    \n",
      "   <chr>                 <dbl>   <dbl>   <dbl>   <dbl>           <dbl> <chr>    \n",
      " 1 1987-12-10 12:00:00   -35.4   -33.6    143.    145.        17.5     AWI-ESM-…\n",
      " 2 1987-12-11 12:00:00   -35.4   -33.6    143.    145.         0.0153  AWI-ESM-…\n",
      " 3 1987-12-12 12:00:00   -35.4   -33.6    143.    145.        16.7     AWI-ESM-…\n",
      " 4 1987-12-13 12:00:00   -35.4   -33.6    143.    145.         1.63    AWI-ESM-…\n",
      " 5 1987-12-14 12:00:00   -35.4   -33.6    143.    145.         0.897   AWI-ESM-…\n",
      " 6 1987-12-15 12:00:00   -35.4   -33.6    143.    145.         0.109   AWI-ESM-…\n",
      " 7 1987-12-16 12:00:00   -35.4   -33.6    143.    145.         0.0160  AWI-ESM-…\n",
      " 8 1987-12-17 12:00:00   -35.4   -33.6    143.    145.         0.00143 AWI-ESM-…\n",
      " 9 1987-12-18 12:00:00   -35.4   -33.6    143.    145.         0.0213  AWI-ESM-…\n",
      "10 1987-12-19 12:00:00   -35.4   -33.6    143.    145.         4.07    AWI-ESM-…\n",
      "# … with 62,467,833 more rows\n",
      "CPU times: user 10.9 s, sys: 5.45 s, total: 16.4 s\n",
      "Wall time: 14.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R\n",
    "print(ds %>% collect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We also tried other approaches, the reason that we chose this approach over others is that:\n",
    "- 1. Arrow exchange: It is slower than feather file. It used around 40 seconds on my laptop.\n",
    "- 2. Pandas exchange: This approach is the most slow among all methods, I waited about 40 minutes and I gave up because it hadn't stopped running by that time.\n",
    "- 3. Parquet file: Parquet files are mainly suitable for long term storage whereas feather files are used in short term storage such as dataframe transfers.\n",
    "Besides, in terms of time, transfer pandas dataframe to parquet took much longer time than to feather file. In terms of storage memory, Parquet files is much smaller than Feather files which can save some memory space for long term storage."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f14e0129284baee33e181c84cc9d0bde2f4d5d150c38a0731cd7f961ea43cb0c"
  },
  "kernelspec": {
   "display_name": "Python [conda env:525_2022]",
   "language": "python",
   "name": "conda-env-525_2022-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
